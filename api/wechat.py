"""
å¾®ä¿¡å…¬ä¼—å·è®°è´¦æœºå™¨äºº - Webhook å…¥å£
"""
import os
import io
import hmac
import hashlib
import time
import json
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo
from urllib.parse import unquote

from fastapi import FastAPI, Request, Response
from fastapi.responses import StreamingResponse
from openpyxl import Workbook
import httpx

app = FastAPI()

# ============ é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰============
APPID = os.environ.get("WECHAT_APPID", "")
APPSECRET = os.environ.get("WECHAT_APPSECRET", "")
TOKEN = os.environ.get("WECHAT_TOKEN", "")
SUPABASE_URL = os.environ.get("SUPABASE_URL", "")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY", "")
PUBLIC_BASE_URL = os.environ.get("PUBLIC_BASE_URL", "").rstrip("/")
RETENTION_DAYS = 38
ARCHIVE_BATCH = 200
EXPORT_TTL_SECONDS = 600
LOCAL_TZ = ZoneInfo("Asia/Shanghai")

# ============ åˆ†ç±»å…³é”®è¯æ˜ å°„ ============
CATEGORY_KEYWORDS = {
    "é¤é¥®": ["æ—©é¤", "åˆé¤", "æ™šé¤", "æ—©é¥­", "åˆé¥­", "æ™šé¥­", "åƒé¥­", "å¤–å–", "é¥­", "é¤", "å¥¶èŒ¶", "å’–å•¡", "é¥®æ–™", "é›¶é£Ÿ", "æ°´æœ", "èœ", "è‚‰", "é¢", "ç²‰", "ç«é”…", "çƒ§çƒ¤", "å°åƒ"],
    "äº¤é€š": ["æ‰“è½¦", "æ»´æ»´", "å‡ºç§Ÿè½¦", "åœ°é“", "å…¬äº¤", "å…¬è½¦", "æ²¹è´¹", "åŠ æ²¹", "åœè½¦", "é«˜é€Ÿ", "è¿‡è·¯è´¹", "å•è½¦", "å…±äº«", "è½¦è´¹", "äº¤é€š"],
    "è´­ç‰©": ["æ·˜å®", "äº¬ä¸œ", "æ‹¼å¤šå¤š", "è´­ç‰©", "ä¹°", "è¡£æœ", "é‹", "åŒ…", "æ—¥ç”¨å“", "è¶…å¸‚", "å•†åœº"],
    "å¨±ä¹": ["ç”µå½±", "æ¸¸æˆ", "ktv", "å”±æ­Œ", "æ—…æ¸¸", "é—¨ç¥¨", "å¨±ä¹", "ç©"],
    "å±…ä½": ["æˆ¿ç§Ÿ", "æ°´è´¹", "ç”µè´¹", "ç‡ƒæ°”", "ç‰©ä¸š", "ç½‘è´¹", "å®½å¸¦"],
    "åŒ»ç–—": ["åŒ»é™¢", "è¯", "çœ‹ç—…", "ä½“æ£€", "åŒ»ç–—"],
    "æ•™è‚²": ["ä¹¦", "è¯¾ç¨‹", "åŸ¹è®­", "å­¦ä¹ ", "æ•™è‚²"],
}

# ============ æ•°æ®åº“æ“ä½œï¼ˆä½¿ç”¨ REST APIï¼‰============
def get_supabase_client():
    """åˆ›å»ºç®€å•çš„ Supabase REST å®¢æˆ·ç«¯"""
    class SupabaseClient:
        def __init__(self, url, key):
            self.url = url.rstrip('/')
            self.key = key
            self.headers = {
                "apikey": key,
                "Authorization": f"Bearer {key}",
                "Content-Type": "application/json",
                "Prefer": "return=representation"
            }
        
        def table(self, name):
            return SupabaseTable(self.url, name, self.headers)
    
    class SupabaseTable:
        def __init__(self, base_url, name, headers):
            self.url = f"{base_url}/rest/v1/{name}"
            self.headers = headers
        
        def insert(self, data):
            class Result:
                def __init__(self, data):
                    self.data = data
                def execute(self):
                    return self
            
            response = httpx.post(self.url, json=data, headers=self.headers, timeout=10.0)
            response.raise_for_status()
            return Result(response.json() if response.content else [data])
        
        def select(self, columns="*"):
            return QueryBuilder(self.url, self.headers, columns)

        def update(self, data):
            return UpdateBuilder(self.url, self.headers, data)

        def delete(self):
            return DeleteBuilder(self.url, self.headers)
    
    class QueryBuilder:
        def __init__(self, url, headers, columns):
            self.url = url
            self.headers = headers
            self.params = {"select": columns}
            self.filters = []
        
        def eq(self, column, value):
            self.filters.append((column, "eq", value))
            return self
        
        def gte(self, column, value):
            self.filters.append((column, "gte", value))
            return self
        
        def lt(self, column, value):
            self.filters.append((column, "lt", value))
            return self

        def ilike(self, column, value):
            self.filters.append((column, "ilike", value))
            return self

        def lte(self, column, value):
            self.filters.append((column, "lte", value))
            return self
        
        def order(self, column, desc=False):
            self.params["order"] = f"{column}.{'desc' if desc else 'asc'}"
            return self

        def limit(self, count: int):
            self.params["limit"] = str(count)
            return self
        
        def execute(self):
            for column, op, value in self.filters:
                self.params[column] = f"{op}.{value}"
            
            response = httpx.get(self.url, params=self.params, headers=self.headers, timeout=10.0)
            response.raise_for_status()
            class Result:
                def __init__(self, data):
                    self.data = data
            return Result(response.json())

    class UpdateBuilder:
        def __init__(self, url, headers, data):
            self.url = url
            self.headers = headers
            self.data = data
            self.params = {}
            self.filters = []

        def eq(self, column, value):
            self.filters.append((column, "eq", value))
            return self

        def execute(self):
            for column, op, value in self.filters:
                self.params[column] = f"{op}.{value}"

            response = httpx.patch(self.url, params=self.params, json=self.data, headers=self.headers, timeout=10.0)
            response.raise_for_status()
            class Result:
                def __init__(self, data):
                    self.data = data
            return Result(response.json() if response.content else [])

    class DeleteBuilder:
        def __init__(self, url, headers):
            self.url = url
            self.headers = headers
            self.params = {}
            self.filters = []

        def eq(self, column, value):
            self.filters.append((column, "eq", value))
            return self

        def execute(self):
            for column, op, value in self.filters:
                self.params[column] = f"{op}.{value}"

            response = httpx.delete(self.url, params=self.params, headers=self.headers, timeout=10.0)
            response.raise_for_status()
            class Result:
                def __init__(self, data):
                    self.data = data
            return Result(response.json() if response.content else [])
    
    return SupabaseClient(SUPABASE_URL, SUPABASE_KEY)


def add_record(openid: str, nickname: str, amount: float, category: str, description: str, created_at: datetime = None):
    """æ·»åŠ è®°è´¦è®°å½•"""
    try:
        archive_old_records()
        supabase = get_supabase_client()
        created_at_value = (created_at or datetime.now(LOCAL_TZ)).isoformat()
        data = {
            "openid": openid,
            "nickname": nickname,
            "amount": amount,
            "category": category,
            "description": description,
            "created_at": created_at_value
        }
        result = supabase.table("records").insert(data).execute()
        return result
    except Exception as e:
        print(f"æ•°æ®åº“é”™è¯¯: {str(e)[:100]}")
        raise


def get_records(start_date: datetime = None, end_date: datetime = None, category: str = None, limit: int = None):
    """æŸ¥è¯¢è®°å½•ï¼ˆæ‰€æœ‰äººå…±åŒï¼‰"""
    try:
        supabase = get_supabase_client()
        query = supabase.table("records").select("*")
        
        if start_date:
            query = query.gte("created_at", start_date.isoformat())
        if end_date:
            query = query.lte("created_at", end_date.isoformat())
        if category:
            query = query.eq("category", category)
        
        query = query.order("created_at", desc=True)
        if limit:
            query = query.limit(limit)
        result = query.execute()
        return result.data
    except Exception as e:
        print(f"æŸ¥è¯¢é”™è¯¯: {str(e)[:100]}")
        return []


def get_records_by_keyword(start_date: datetime = None, end_date: datetime = None, keyword: str = "", limit: int = None):
    """æŒ‰æè¿°å…³é”®è¯æŸ¥è¯¢è®°å½•"""
    try:
        supabase = get_supabase_client()
        query = supabase.table("records").select("*")

        if start_date:
            query = query.gte("created_at", start_date.isoformat())
        if end_date:
            query = query.lte("created_at", end_date.isoformat())
        if keyword:
            query = query.ilike("description", f"*{keyword}*")

        query = query.order("created_at", desc=True)
        if limit:
            query = query.limit(limit)
        result = query.execute()
        return result.data
    except Exception as e:
        print(f"å…³é”®è¯æŸ¥è¯¢é”™è¯¯: {str(e)[:100]}")
        return []


def get_statistics(start_date: datetime = None, end_date: datetime = None):
    """è·å–ç»Ÿè®¡æ•°æ®ï¼ˆæ‰€æœ‰äººå…±åŒï¼‰"""
    records = get_records(start_date, end_date)
    
    total = sum(r["amount"] for r in records)
    by_category = {}
    by_user = {}
    max_record = None
    
    for r in records:
        cat = r["category"]
        by_category[cat] = by_category.get(cat, 0) + r["amount"]
        nickname = r.get("nickname", "")
        openid = r.get("openid", "")
        if nickname and nickname != openid[:8]:
            by_user[nickname] = by_user.get(nickname, 0) + r["amount"]
        if not max_record or r["amount"] > max_record["amount"]:
            max_record = r
    
    return {
        "total": total,
        "by_category": by_category,
        "by_user": by_user,
        "count": len(records),
        "max_record": max_record,
        "latest_record": records[0] if records else None
    }


def to_local_datetime(value: str) -> datetime:
    """è§£æå¹¶è½¬ä¸ºåŒ—äº¬æ—¶é—´"""
    dt = datetime.fromisoformat(value.replace("Z", "+00:00"))
    if dt.tzinfo is None:
        return dt.replace(tzinfo=LOCAL_TZ)
    return dt.astimezone(LOCAL_TZ)


def parse_date_token(token: str) -> datetime:
    """è§£ææ—¥æœŸæ ‡è®°ï¼ˆæ”¯æŒ ä»Šå¤©/æ˜¨å¤©/æœ¬æœˆ/æœ¬å‘¨/MM-DDï¼‰"""
    now = datetime.now(LOCAL_TZ)
    if token in ["ä»Šå¤©", "ä»Šæ—¥"]:
        return now.replace(hour=0, minute=0, second=0, microsecond=0)
    if token in ["æ˜¨å¤©", "æ˜¨æ—¥"]:
        return (now - timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
    if token == "æœ¬å‘¨":
        today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
        return today_start - timedelta(days=today_start.weekday())
    if token == "æœ¬æœˆ":
        return now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)

    if "-" in token:
        try:
            month, day = token.split("-", 1)
            month = int(month)
            day = int(day)
            dt = now.replace(month=month, day=day, hour=0, minute=0, second=0, microsecond=0)
            if dt > now:
                dt = dt.replace(year=dt.year - 1)
            return dt
        except Exception:
            return None
    return None


def update_record(record_id: int, amount: float, category: str, description: str):
    """æ›´æ–°è®°è´¦è®°å½•"""
    supabase = get_supabase_client()
    data = {
        "amount": amount,
        "category": category,
        "description": description
    }
    return supabase.table("records").update(data).eq("id", record_id).execute()


def delete_record(record_id: int):
    """åˆ é™¤è®°è´¦è®°å½•"""
    supabase = get_supabase_client()
    return supabase.table("records").delete().eq("id", record_id).execute()


def archive_deleted_record(record: dict, deleted_by: str):
    """ä¿å­˜å·²åˆ é™¤è®°å½•åˆ°å›æ”¶ç«™"""
    supabase = get_supabase_client()
    data = {
        "original_id": record["id"],
        "deleted_by": deleted_by,
        "openid": record.get("openid", ""),
        "nickname": record.get("nickname", ""),
        "amount": record.get("amount", 0),
        "category": record.get("category", ""),
        "description": record.get("description", ""),
        "created_at": record.get("created_at", ""),
        "deleted_at": datetime.now(LOCAL_TZ).isoformat()
    }
    supabase.table("records_deleted").insert(data).execute()


def get_deleted_records(deleted_by: str, limit: int = 10):
    """è·å–å›æ”¶ç«™è®°å½•"""
    try:
        supabase = get_supabase_client()
        result = (
            supabase.table("records_deleted")
            .select("*")
            .eq("deleted_by", deleted_by)
            .order("deleted_at", desc=True)
            .execute()
        )
        return result.data[:limit]
    except Exception as e:
        print(f"å›æ”¶ç«™æŸ¥è¯¢é”™è¯¯: {str(e)[:100]}")
        return []


def restore_deleted_record(deleted_by: str, index: int):
    """ä»å›æ”¶ç«™æ¢å¤è®°å½•"""
    supabase = get_supabase_client()
    records = get_deleted_records(deleted_by, limit=20)
    if index < 1 or index > len(records):
        return {"error": "invalid"}
    record = records[index - 1]
    insert_data = {
        "openid": record.get("openid", ""),
        "nickname": record.get("nickname", ""),
        "amount": record.get("amount", 0),
        "category": record.get("category", ""),
        "description": record.get("description", ""),
        "created_at": record.get("created_at", "")
    }
    supabase.table("records").insert(insert_data).execute()
    supabase.table("records_deleted").delete().eq("id", record["id"]).execute()
    return {"restored": record}


def get_daily_total(record_date: str):
    """è·å–æŒ‰å¤©æ±‡æ€»æ•°æ®"""
    try:
        supabase = get_supabase_client()
        result = supabase.table("daily_totals").select("*").eq("record_date", record_date).execute()
        return result.data[0] if result.data else None
    except Exception as e:
        print(f"æ±‡æ€»æŸ¥è¯¢é”™è¯¯: {str(e)[:100]}")
        return None


def add_daily_total(record_date: str, amount: float):
    """æ–°å¢æˆ–ç´¯åŠ æ—¥æ±‡æ€»"""
    supabase = get_supabase_client()
    now = datetime.now(LOCAL_TZ).isoformat()
    existing = get_daily_total(record_date)
    if existing:
        new_total = float(existing.get("total_amount", 0)) + amount
        supabase.table("daily_totals").update({
            "total_amount": new_total,
            "updated_at": now
        }).eq("record_date", record_date).execute()
        return new_total

    supabase.table("daily_totals").insert({
        "record_date": record_date,
        "total_amount": amount,
        "updated_at": now
    }).execute()
    return amount


def archive_old_records():
    """å½’æ¡£è¶…è¿‡ä¿ç•™å¤©æ•°çš„æ˜ç»†ï¼Œåªä¿ç•™é‡‘é¢æ±‡æ€»"""
    try:
        supabase = get_supabase_client()
        cutoff = datetime.now(LOCAL_TZ) - timedelta(days=RETENTION_DAYS)
        records = (
            supabase.table("records")
            .select("*")
            .lte("created_at", cutoff.isoformat())
            .order("created_at", desc=False)
            .limit(ARCHIVE_BATCH)
            .execute()
            .data
        )
        if not records:
            return 0

        totals_by_date = {}
        for r in records:
            dt = to_local_datetime(r["created_at"])
            date_key = dt.strftime("%Y-%m-%d")
            totals_by_date[date_key] = totals_by_date.get(date_key, 0) + float(r["amount"])

        for date_key, amount in totals_by_date.items():
            add_daily_total(date_key, amount)

        for r in records:
            delete_record(r["id"])

        return len(records)
    except Exception as e:
        print(f"å½’æ¡£é”™è¯¯: {str(e)[:100]}")
        return 0


def get_debt(name: str):
    """è·å–æŒ‡å®šäººçš„æ¬ æ¬¾è®°å½•ï¼ˆæˆ‘æ¬ åˆ«äººï¼‰"""
    try:
        supabase = get_supabase_client()
        result = supabase.table("debts").select("*").eq("name", name).execute()
        return result.data[0] if result.data else None
    except Exception as e:
        print(f"å¤–å€ºæŸ¥è¯¢é”™è¯¯: {str(e)[:100]}")
        return None


def add_debt(name: str, amount: float, note: str = ""):
    """æ–°å¢æˆ–ç´¯åŠ æ¬ æ¬¾ï¼ˆæˆ‘æ¬ åˆ«äººï¼‰"""
    supabase = get_supabase_client()
    now = datetime.now(LOCAL_TZ).isoformat()
    existing = get_debt(name)
    if existing:
        new_amount = float(existing.get("amount", 0)) + amount
        data = {
            "amount": new_amount,
            "status": "active",
            "updated_at": now
        }
        if note:
            data["note"] = note
        supabase.table("debts").update(data).eq("name", name).execute()
        return new_amount

    data = {
        "name": name,
        "amount": amount,
        "status": "active",
        "note": note,
        "created_at": now,
        "updated_at": now
    }
    supabase.table("debts").insert(data).execute()
    return amount


def repay_debt(name: str, amount: float):
    """è¿˜é’±æ‰£å‡æ¬ æ¬¾ï¼ˆæˆ‘æ¬ åˆ«äººï¼‰"""
    supabase = get_supabase_client()
    now = datetime.now(LOCAL_TZ).isoformat()
    existing = get_debt(name)
    if not existing:
        return {"error": "not_found"}

    balance = float(existing.get("amount", 0))
    if amount > balance:
        return {"error": "overpay", "balance": balance}

    new_balance = balance - amount
    status = "paid" if new_balance == 0 else "active"
    data = {
        "amount": new_balance,
        "status": status,
        "updated_at": now
    }
    supabase.table("debts").update(data).eq("name", name).execute()
    return {"balance": new_balance, "status": status}


def list_debts():
    """åˆ—å‡ºæ‰€æœ‰æœªæ¸…æ¬ æ¬¾ï¼ˆæˆ‘æ¬ åˆ«äººï¼‰"""
    try:
        supabase = get_supabase_client()
        result = supabase.table("debts").select("*").eq("status", "active").order("amount", desc=True).execute()
        return result.data
    except Exception as e:
        print(f"å¤–å€ºåˆ—è¡¨é”™è¯¯: {str(e)[:100]}")
        return []


# ============ æ¶ˆæ¯è§£æ ============
def parse_category(text: str) -> str:
    """ä»æ–‡æœ¬ä¸­è¯†åˆ«åˆ†ç±»"""
    text_lower = text.lower()
    for category, keywords in CATEGORY_KEYWORDS.items():
        for keyword in keywords:
            if keyword in text_lower:
                return category
    return "å…¶ä»–"


def parse_record_text(text: str) -> dict:
    """è§£æè®°è´¦æ–‡æœ¬ï¼Œè¿”å› dict æˆ– unknown"""
    import re
    text = text.strip()

    # åˆ†ç±» æè¿° é‡‘é¢ï¼ˆæ‰‹åŠ¨åˆ†ç±»ä¼˜å…ˆï¼‰
    explicit_match = re.match(r'^(\S+)\s+(.+?)\s+(\d+(?:\.\d+)?)$', text)
    if explicit_match:
        category, desc, amount = explicit_match.groups()
        return {
            "type": "record",
            "amount": float(amount),
            "description": desc.strip(),
            "category": category.strip()
        }

    # æè¿° é‡‘é¢ï¼ˆæŒ‰æè¿°è‡ªåŠ¨åˆ†ç»„ï¼‰
    simple_match = re.match(r'^(\S+)\s+(\d+(?:\.\d+)?)$', text)
    if simple_match:
        desc, amount = simple_match.groups()
        return {
            "type": "record",
            "amount": float(amount),
            "description": desc.strip(),
            "category": desc.strip()
        }

    # è®°è´¦ï¼šå°è¯•è§£æé‡‘é¢
    patterns = [
        r'^(.+?)\s+(\d+(?:\.\d+)?)\s*(.*)$',  # æè¿° é‡‘é¢ [åˆ†ç±»]
        r'^(\d+(?:\.\d+)?)\s+(.+?)$',          # é‡‘é¢ æè¿°
        r'^(.+?)(\d+(?:\.\d+)?)$',             # æè¿°é‡‘é¢ï¼ˆæ— ç©ºæ ¼ï¼‰
        r'^(\d+(?:\.\d+)?)(.+?)$',             # é‡‘é¢æè¿°ï¼ˆæ— ç©ºæ ¼ï¼‰
    ]

    for i, pattern in enumerate(patterns):
        match = re.match(pattern, text)
        if match:
            groups = match.groups()
            if i == 0:  # æè¿° é‡‘é¢ [åˆ†ç±»]
                desc, amount, extra = groups
                amount = float(amount)
                category = extra.strip() if extra.strip() else desc.strip()
            elif i == 1:  # é‡‘é¢ æè¿°
                amount, desc = groups
                amount = float(amount)
                category = desc.strip()
            elif i == 2:  # æè¿°é‡‘é¢
                desc, amount = groups
                amount = float(amount)
                category = desc.strip()
            else:  # é‡‘é¢æè¿°
                amount, desc = groups
                amount = float(amount)
                category = desc.strip()

            return {
                "type": "record",
                "amount": amount,
                "description": desc.strip(),
                "category": category
            }

    return {"type": "unknown"}


def parse_message(content: str) -> dict:
    """è§£æç”¨æˆ·æ¶ˆæ¯"""
    import re
    content = content.strip()
    
    # æŸ¥è¯¢å‘½ä»¤
    if content in ["ä»Šæ—¥", "ä»Šå¤©"]:
        return {"type": "query", "period": "today"}
    if content in ["æ˜¨æ—¥", "æ˜¨å¤©"]:
        return {"type": "query", "period": "yesterday"}
    if content in ["ä¸ƒå¤©", "è¿‘ä¸ƒå¤©"]:
        return {"type": "query", "period": "7days"}
    if content in ["åŠä¸ªæœˆ", "åäº”å¤©", "è¿‘åŠä¸ªæœˆ"]:
        return {"type": "query", "period": "15days"}
    if content in ["ä¸€ä¸ªæœˆ", "è¿‘ä¸€ä¸ªæœˆ", "30å¤©"]:
        return {"type": "query", "period": "30days"}
    if content in ["æœ¬å‘¨", "è¿™å‘¨"]:
        return {"type": "query", "period": "week"}
    if content in ["æœ¬æœˆ", "è¿™ä¸ªæœˆ"]:
        return {"type": "query", "period": "month"}
    if content in ["æ˜ç»†", "è¯¦æƒ…", "è®°å½•"]:
        return {"type": "detail", "period": "today"}
    if content.startswith("æ˜ç»† "):
        return {"type": "detail", "period": content.split(maxsplit=1)[1].strip()}
    if content in ["å¸®åŠ©", "help", "?"]:
        return {"type": "help"}
    if content == "ç»Ÿè®¡":
        return {"type": "query", "period": "7days"}

    # å¯¼å‡º
    export_excel_match = re.match(r'^(å¯¼å‡ºexcel|å¯¼å‡ºExcel|å¯¼å‡ºè¡¨æ ¼)\s*(.*)$', content)
    if export_excel_match:
        target = export_excel_match.group(2)
        return {"type": "export", "target": target.strip() if target else ""}

    export_match = re.match(r'^å¯¼å‡º(?:\s+(.+))?$', content)
    if export_match:
        target = export_match.group(1)
        return {"type": "export", "target": target.strip() if target else ""}

    # è¡¥è®°ï¼ˆæ˜¨å¤©/æ—¥æœŸï¼‰
    backfill_match = re.match(r'^è¡¥è®°\s+(\S+)\s+(.+)$', content)
    if backfill_match:
        date_token = backfill_match.group(1).strip()
        rest = backfill_match.group(2).strip()
        parsed = parse_record_text(rest)
        if parsed["type"] == "record":
            return {
                "type": "record_backfill",
                "date_token": date_token,
                "amount": parsed["amount"],
                "description": parsed["description"],
                "category": parsed["category"]
            }
        return {"type": "unknown"}

    # è®°å½•ä¿®æ”¹/åˆ é™¤
    edit_match = re.match(r'^(æ”¹|ä¿®æ”¹)\s+(\d+)\s+(.+)$', content)
    if edit_match:
        index = int(edit_match.group(2))
        rest = edit_match.group(3).strip()
        parsed = parse_record_text(rest)
        if parsed["type"] == "record":
            return {
                "type": "record_edit",
                "index": index,
                "amount": parsed["amount"],
                "description": parsed["description"],
                "category": parsed["category"]
            }
        return {"type": "unknown"}

    delete_match = re.match(r'^(åˆ |åˆ é™¤)\s+(.+)$', content)
    if delete_match:
        return {"type": "record_delete", "raw": delete_match.group(2).strip()}

    if content == "å›æ”¶ç«™":
        return {"type": "deleted_list"}

    restore_match = re.match(r'^æ¢å¤\s+(\d+)$', content)
    if restore_match:
        return {"type": "restore_deleted", "index": int(restore_match.group(1))}

    # å¤–å€ºç›¸å…³ï¼ˆæˆ‘æ¬ åˆ«äººï¼‰
    debt_add_match = re.match(r'^æ¬ \s+(\S+)\s+(\d+(?:\.\d+)?)\s*(.*)$', content)
    if debt_add_match:
        name, amount, note = debt_add_match.groups()
        return {"type": "debt_add", "name": name, "amount": float(amount), "note": note.strip()}

    debt_repay_match = re.match(r'^è¿˜\s+(\S+)\s+(\d+(?:\.\d+)?)$', content)
    if debt_repay_match:
        name, amount = debt_repay_match.groups()
        return {"type": "debt_repay", "name": name, "amount": float(amount)}

    debt_query_match = re.match(r'^æŸ¥è¯¢å¤–å€º$', content)
    if debt_query_match:
        return {"type": "debt_query_all"}

    # è‡ªå®šä¹‰åˆ†ç±»æŸ¥è¯¢
    if content.startswith("åˆ†ç±» "):
        return {"type": "query_category", "category": content.split(maxsplit=1)[1].strip()}
    if content.startswith("ç»Ÿè®¡ "):
        target = content.split(maxsplit=1)[1].strip()
        if target in ["ä»Šæ—¥", "æ˜¨å¤©", "æ˜¨æ—¥", "ä¸ƒå¤©", "è¿‘ä¸ƒå¤©", "åŠä¸ªæœˆ", "åäº”å¤©", "è¿‘åŠä¸ªæœˆ", "ä¸€ä¸ªæœˆ", "è¿‘ä¸€ä¸ªæœˆ", "æœ¬å‘¨", "æœ¬æœˆ"]:
            mapping = {
                "ä»Šæ—¥": "today",
                "æ˜¨å¤©": "yesterday",
                "æ˜¨æ—¥": "yesterday",
                "ä¸ƒå¤©": "7days",
                "è¿‘ä¸ƒå¤©": "7days",
                "åŠä¸ªæœˆ": "15days",
                "åäº”å¤©": "15days",
                "è¿‘åŠä¸ªæœˆ": "15days",
                "ä¸€ä¸ªæœˆ": "30days",
                "è¿‘ä¸€ä¸ªæœˆ": "30days",
                "æœ¬å‘¨": "week",
                "æœ¬æœˆ": "month"
            }
            return {"type": "query", "period": mapping[target]}
        return {"type": "query_category", "category": target}
    
    # åˆ†ç±»æŸ¥è¯¢
    for category in CATEGORY_KEYWORDS.keys():
        if content == category:
            return {"type": "query_category", "category": category}
    
    return parse_record_text(content)


def get_date_range(period: str):
    """è·å–æ—¥æœŸèŒƒå›´"""
    now = datetime.now(LOCAL_TZ)
    today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
    
    if period == "today":
        return today_start, now
    elif period == "yesterday":
        yesterday_start = today_start - timedelta(days=1)
        yesterday_end = today_start - timedelta(seconds=1)
        return yesterday_start, yesterday_end
    elif period == "7days":
        return now - timedelta(days=7), now
    elif period == "15days":
        return now - timedelta(days=15), now
    elif period == "30days":
        return now - timedelta(days=30), now
    elif period == "week":
        week_start = today_start - timedelta(days=today_start.weekday())
        return week_start, now
    elif period == "month":
        month_start = today_start.replace(day=1)
        return month_start, now
    return None, None


def format_statistics(stats: dict, period_name: str, start_date: datetime, end_date: datetime) -> str:
    """æ ¼å¼åŒ–ç»Ÿè®¡ä¿¡æ¯"""
    if stats["count"] == 0:
        return f"ğŸ“Š {period_name}æš‚æ— è®°å½•"
    
    range_text = f"{start_date.strftime('%m-%d')} ~ {end_date.strftime('%m-%d')}"
    avg = stats["total"] / stats["count"] if stats["count"] else 0
    lines = [
        f"ğŸ“Š {period_name}ç»Ÿè®¡ï¼ˆ{range_text}ï¼‰",
        f"ğŸ’° æ€»æ”¯å‡ºï¼š{stats['total']:.2f} å…ƒ",
        ""
    ]
    
    # æŒ‰åˆ†ç±»
    if stats["by_category"]:
        top_categories = sorted(stats["by_category"].items(), key=lambda x: -x[1])
        for cat, amount in top_categories:
            lines.append(f"{cat} {amount:.2f}")
    
    return "\n".join(lines)


def format_records(records: list, limit: int = 20) -> str:
    """æ ¼å¼åŒ–è®°å½•åˆ—è¡¨"""
    if not records:
        return "ğŸ“ æš‚æ— è®°å½•"
    
    lines = ["ğŸ“ æœ€è¿‘è®°å½•ï¼ˆå…±åŒï¼‰ï¼š"]
    for i, r in enumerate(records[:limit], start=1):
        dt = to_local_datetime(r["created_at"])
        date_str = dt.strftime("%m-%d %H:%M")
        lines.append(f"{i}. {date_str} {r['description']} {r['amount']:.2f}å…ƒ [{r['category']}]")
    
    if len(records) > limit:
        lines.append(f"  ... å…± {len(records)} æ¡è®°å½•")
    
    return "\n".join(lines)


def build_export_signature(openid: str, period: str, ts: int) -> str:
    """ç”Ÿæˆå¯¼å‡ºé“¾æ¥ç­¾å"""
    payload = f"{openid}|{period}|{ts}"
    return hmac.new(TOKEN.encode("utf-8"), payload.encode("utf-8"), hashlib.sha256).hexdigest()


def build_export_link(openid: str, period: str) -> str:
    """ç”Ÿæˆå¯¼å‡º Excel çš„ä¸´æ—¶é“¾æ¥"""
    if not PUBLIC_BASE_URL:
        return ""
    ts = int(time.time())
    sig = build_export_signature(openid, period, ts)
    return f"{PUBLIC_BASE_URL}/api/export?openid={openid}&period={period}&ts={ts}&sig={sig}"


def verify_export_signature(openid: str, period: str, ts: str, sig: str) -> bool:
    """æ ¡éªŒå¯¼å‡ºé“¾æ¥ç­¾åä¸æœ‰æ•ˆæœŸ"""
    if not openid or not period or not ts or not sig:
        return False
    try:
        ts_int = int(ts)
    except ValueError:
        return False
    if abs(int(time.time()) - ts_int) > EXPORT_TTL_SECONDS:
        return False
    expected = build_export_signature(openid, period, ts_int)
    return hmac.compare_digest(expected, sig)


def build_export_excel_bytes(records: list, start_date: datetime, end_date: datetime, limit: int = 1000) -> bytes:
    """å¯¼å‡º Excelï¼ˆäºŒè¿›åˆ¶ï¼‰"""
    wb = Workbook()
    ws = wb.active
    ws.title = "ç»Ÿè®¡"

    # æœŸé—´ä¸ç±»ç›®ç»Ÿè®¡
    ws.append(["ç»Ÿè®¡åŒºé—´", f"{start_date.strftime('%m-%d')} ~ {end_date.strftime('%m-%d')}"])
    ws.append([])

    category_totals = {}
    daily_totals = {}
    for r in records[:limit]:
        dt = to_local_datetime(r["created_at"])
        day_key = f"{dt.month}.{dt.day}"
        category = r["category"]
        amount = float(r["amount"])
        category_totals[category] = category_totals.get(category, 0) + amount
        daily_totals[day_key] = daily_totals.get(day_key, 0) + amount

    ws.append(["æ¯æ—¥åˆè®¡"])
    ws.append(["æ—¥æœŸ", "é‡‘é¢"])
    for day, amount in sorted(daily_totals.items()):
        ws.append([day, f"èŠ±è´¹{round(amount, 2)}"])

    ws.append([])
    ws.append(["ç±»ç›®ç»Ÿè®¡"])
    ws.append(["ç±»ç›®", "é‡‘é¢"])
    for cat, amount in sorted(category_totals.items(), key=lambda x: -x[1]):
        ws.append([cat, round(amount, 2)])

    ws.append([])
    ws.append(["æ¯å¤©æ˜ç»†"])
    ws.append(["æ—¥æœŸ", "æè¿°", "é‡‘é¢", "åˆ†ç±»"])
    for r in records[:limit]:
        dt = to_local_datetime(r["created_at"])
        date_str = f"{dt.month}.{dt.day}"
        ws.append([date_str, r["description"], float(r["amount"]), r["category"]])

    bio = io.BytesIO()
    wb.save(bio)
    bio.seek(0)
    return bio.read()


def format_debts(debts: list) -> str:
    """æ ¼å¼åŒ–å¤–å€ºåˆ—è¡¨"""
    if not debts:
        return "ğŸ“Œ å¤–å€ºæ€»è§ˆï¼šæš‚æ— æ¬ æ¬¾"

    total = sum(float(d.get("amount", 0)) for d in debts)
    lines = ["ğŸ“Œ å¤–å€ºæ€»è§ˆï¼ˆæˆ‘æ¬ åˆ«äººï¼‰"]
    for d in debts:
        lines.append(f"  â€¢ {d['name']}ï¼š{float(d['amount']):.2f} å…ƒ")
    lines.append(f"åˆè®¡ï¼š{total:.2f} å…ƒ")
    return "\n".join(lines)


def get_help_text() -> str:
    """è¿”å›å¸®åŠ©ä¿¡æ¯"""
    return """ğŸ“– è®°è´¦æœºå™¨äººä½¿ç”¨æŒ‡å—

ã€è®°è´¦ã€‘
å‘é€ï¼šåˆ†ç±» æè¿° é‡‘é¢
ä¾‹å¦‚ï¼šå¤œå®µ é¸¡é”éª¨ 18
      å¤œå®µ æ³¡é¢ 18
      ä¹°èœ è¥¿çº¢æŸ¿ 25
ä¹Ÿæ”¯æŒï¼šæè¿° é‡‘é¢ / é‡‘é¢ æè¿°ï¼ˆè‡ªåŠ¨åˆ†ç±»ï¼‰

ã€æŸ¥è¯¢ç»Ÿè®¡ã€‘
å‘é€ï¼šä»Šæ—¥ / æ˜¨æ—¥ / ä¸ƒå¤© / åŠä¸ªæœˆ / ä¸€ä¸ªæœˆ / æœ¬å‘¨ / æœ¬æœˆ

ã€æŸ¥çœ‹æ˜ç»†ã€‘
å‘é€ï¼šæ˜ç»† / æ˜ç»† æ˜¨å¤© / æ˜ç»† 01-21

ã€ä¿®æ”¹/åˆ é™¤è®°å½•ã€‘
å‘é€ï¼šæ”¹ 1 å¤œå®µ é¸¡é”éª¨ 16
å‘é€ï¼šåˆ  2 / åˆ  1-4 / åˆ  æ˜¨å¤© 1-3
å‘é€ï¼šå›æ”¶ç«™ / æ¢å¤ 1
ã€è¡¥è®°ã€‘
å‘é€ï¼šè¡¥è®° æ˜¨å¤© ä¹°çƒŸ 50
å‘é€ï¼šè¡¥è®° 01-21 ä¹°çƒŸ 50

ã€æŒ‰åˆ†ç±»æŸ¥è¯¢ã€‘
å‘é€ï¼šåˆ†ç±» å¤œå®µ / ç»Ÿè®¡ å¤œå®µ
æˆ–å‘é€åˆ†ç±»åï¼šé¤é¥® / äº¤é€š / è´­ç‰© / å¨±ä¹ / å±…ä½ / åŒ»ç–— / æ•™è‚²

ã€å¤–å€ºï¼ˆæˆ‘æ¬ åˆ«äººï¼‰ã€‘
æ¬  å¼ ä¸‰ 1000
è¿˜ å¼ ä¸‰ 100
æŸ¥è¯¢å¤–å€º

ã€å¯¼å‡ºExcelã€‘
å‘é€ï¼šå¯¼å‡º ä»Šæ—¥ / æ˜¨æ—¥ / ä¸ƒå¤© / åŠä¸ªæœˆ / ä¸€ä¸ªæœˆ
å‘é€ï¼šå¯¼å‡ºè¡¨æ ¼ ä»Šæ—¥ / æ˜¨æ—¥ / ä¸ƒå¤© / åŠä¸ªæœˆ / ä¸€ä¸ªæœˆ

ğŸ’¡ æ‰€æœ‰è®°å½•å…±åŒç»Ÿè®¡ï¼Œæ”¯æŒå¤šäººä½¿ç”¨"""


# ============ å¤„ç†æ¶ˆæ¯ ============
def handle_message(openid: str, nickname: str, content: str) -> str:
    """å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼Œè¿”å›å›å¤å†…å®¹"""
    parsed = parse_message(content)
    
    if parsed["type"] == "help":
        return get_help_text()
    
    elif parsed["type"] == "record":
        try:
            add_record(
                openid=openid,
                nickname=nickname,
                amount=parsed["amount"],
                category=parsed["category"],
                description=parsed["description"]
            )
            return f"âœ… è®°è´¦æˆåŠŸï¼\n{parsed['description']}ï¼š{parsed['amount']:.2f} å…ƒ\nåˆ†ç±»ï¼š{parsed['category']}"
        except Exception as e:
            print(f"è®°è´¦å¤±è´¥: {str(e)[:100]}")
            return "âŒ è®°è´¦å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    elif parsed["type"] == "record_backfill":
        try:
            dt = parse_date_token(parsed["date_token"])
            if not dt:
                return "âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œç¤ºä¾‹ï¼šè¡¥è®° æ˜¨å¤© ä¹°çƒŸ 50 æˆ– è¡¥è®° 01-21 ä¹°çƒŸ 50"
            add_record(
                openid=openid,
                nickname=nickname,
                amount=parsed["amount"],
                category=parsed["category"],
                description=parsed["description"],
                created_at=dt
            )
            return (
                f"âœ… è¡¥è®°æˆåŠŸï¼ˆ{parsed['date_token']}ï¼‰\n"
                f"{parsed['description']}ï¼š{parsed['amount']:.2f} å…ƒ\n"
                f"åˆ†ç±»ï¼š{parsed['category']}"
            )
        except Exception as e:
            print(f"è¡¥è®°å¤±è´¥: {str(e)[:100]}")
            return "âŒ è¡¥è®°å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    elif parsed["type"] == "record_edit":
        try:
            records = get_records(limit=20)
            index = parsed["index"]
            if index < 1 or index > len(records):
                return "âŒ ç¼–å·æ— æ•ˆï¼Œè¯·å…ˆå‘é€ã€Œæ˜ç»†ã€æŸ¥çœ‹ç¼–å·"
            record = records[index - 1]
            result = update_record(record["id"], parsed["amount"], parsed["category"], parsed["description"])
            if not getattr(result, "data", []):
                return "âŒ ä¿®æ”¹å¤±è´¥ï¼Œå¯èƒ½æ²¡æœ‰æƒé™ï¼ˆè¯·æ£€æŸ¥ RLS ç­–ç•¥ï¼‰"
            return f"âœ… å·²ä¿®æ”¹ç¬¬ {index} æ¡\n{parsed['description']}ï¼š{parsed['amount']:.2f} å…ƒ\nåˆ†ç±»ï¼š{parsed['category']}"
        except Exception as e:
            print(f"ä¿®æ”¹è®°å½•å¤±è´¥: {str(e)[:100]}")
            return "âŒ ä¿®æ”¹å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    elif parsed["type"] == "record_delete":
        try:
            def parse_indices(raw: str) -> list:
                raw = raw.replace("ï¼Œ", ",").replace(" ", "")
                parts = [p for p in raw.split(",") if p]
                indices = []
                for part in parts:
                    if "-" in part:
                        start, end = part.split("-", 1)
                        if start.isdigit() and end.isdigit():
                            s = int(start)
                            e = int(end)
                            if s <= e:
                                indices.extend(list(range(s, e + 1)))
                    elif part.isdigit():
                        indices.append(int(part))
                return sorted(set(indices))

            raw = parsed["raw"]
            tokens = raw.split()
            period_token = "ä»Šå¤©"
            if tokens and tokens[0] in ["ä»Šå¤©", "ä»Šæ—¥", "æ˜¨å¤©", "æ˜¨æ—¥", "æœ¬å‘¨", "æœ¬æœˆ"] or ("-" in tokens[0]):
                period_token = tokens[0]
                raw = " ".join(tokens[1:]).strip()
            indices = parse_indices(raw)
            if not indices:
                return "âŒ æ ¼å¼é”™è¯¯ï¼Œç¤ºä¾‹ï¼šåˆ  2 æˆ– åˆ  1,3,5 æˆ– åˆ  1-4 æˆ– åˆ  æ˜¨å¤© 1-3"

            start_date, end_date = get_date_range("today")
            if period_token in ["æ˜¨å¤©", "æ˜¨æ—¥"]:
                start_date, end_date = get_date_range("yesterday")
            elif period_token == "æœ¬å‘¨":
                start_date, end_date = get_date_range("week")
            elif period_token == "æœ¬æœˆ":
                start_date, end_date = get_date_range("month")
            elif "-" in period_token:
                dt = parse_date_token(period_token)
                if dt:
                    start_date = dt
                    end_date = dt + timedelta(days=1) - timedelta(seconds=1)

            records = get_records(start_date=start_date, end_date=end_date, limit=50)
            max_index = len(records)
            invalid = [i for i in indices if i < 1 or i > max_index]
            if invalid:
                return "âŒ ç¼–å·æ— æ•ˆï¼Œè¯·å…ˆå‘é€ã€Œæ˜ç»†ã€æŸ¥çœ‹ç¼–å·"

            deleted = 0
            for i in indices:
                record = records[i - 1]
                archive_deleted_record(record, deleted_by=openid)
                result = delete_record(record["id"])
                if getattr(result, "data", []):
                    deleted += 1

            if deleted == 0:
                return "âŒ åˆ é™¤å¤±è´¥ï¼Œå¯èƒ½æ²¡æœ‰æƒé™ï¼ˆè¯·æ£€æŸ¥ RLS ç­–ç•¥ï¼‰"
            return f"âœ… å·²åˆ é™¤ {deleted} æ¡è®°å½•"
        except Exception as e:
            print(f"åˆ é™¤è®°å½•å¤±è´¥: {str(e)[:100]}")
            return "âŒ åˆ é™¤å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    elif parsed["type"] == "deleted_list":
        try:
            deleted = get_deleted_records(openid, limit=10)
            if not deleted:
                return "ğŸ—‘ï¸ å›æ”¶ç«™ä¸ºç©º"
            lines = ["ğŸ—‘ï¸ å›æ”¶ç«™ï¼ˆæœ€è¿‘10æ¡ï¼‰ï¼š"]
            for i, r in enumerate(deleted, start=1):
                dt = to_local_datetime(r["created_at"])
                date_str = dt.strftime("%m-%d %H:%M")
                lines.append(f"{i}. {date_str} {r['description']} {float(r['amount']):.2f}å…ƒ [{r['category']}]")
            lines.append("å‘é€ï¼šæ¢å¤ 1 è¿›è¡Œæ¢å¤")
            return "\n".join(lines)
        except Exception as e:
            print(f"å›æ”¶ç«™å¤±è´¥: {str(e)[:100]}")
            return "âŒ å›æ”¶ç«™æŸ¥è¯¢å¤±è´¥"

    elif parsed["type"] == "restore_deleted":
        try:
            result = restore_deleted_record(openid, parsed["index"])
            if result.get("error") == "invalid":
                return "âŒ ç¼–å·æ— æ•ˆï¼Œè¯·å…ˆå‘é€ã€Œå›æ”¶ç«™ã€æŸ¥çœ‹ç¼–å·"
            record = result["restored"]
            return f"âœ… å·²æ¢å¤ï¼š{record['description']} {float(record['amount']):.2f}å…ƒ"
        except Exception as e:
            print(f"æ¢å¤å¤±è´¥: {str(e)[:100]}")
            return "âŒ æ¢å¤å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
    
    elif parsed["type"] == "query":
        try:
            start_date, end_date = get_date_range(parsed["period"])
            period_names = {
                "today": "ä»Šæ—¥",
                "yesterday": "æ˜¨æ—¥",
                "7days": "è¿‘ä¸ƒå¤©",
                "15days": "è¿‘åŠä¸ªæœˆ",
                "30days": "è¿‘ä¸€ä¸ªæœˆ",
                "week": "æœ¬å‘¨",
                "month": "æœ¬æœˆ"
            }
            stats = get_statistics(start_date=start_date, end_date=end_date)
            return format_statistics(stats, period_names[parsed["period"]], start_date, end_date)
        except Exception as e:
            print(f"æŸ¥è¯¢å¤±è´¥: {str(e)[:100]}")
            return "âŒ æŸ¥è¯¢å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
    
    elif parsed["type"] == "query_category":
        try:
            now = datetime.now(LOCAL_TZ)
            month_start = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
            records = get_records(start_date=month_start, category=parsed["category"])
            total = sum(r["amount"] for r in records)
            count = len(records)
            avg = total / count if count else 0
            if count > 0:
                result = (
                    f"ğŸ“‚ æœ¬æœˆã€{parsed['category']}ã€‘æ”¯å‡ºï¼š{total:.2f} å…ƒ\n"
                    f"ğŸ§¾ è®°å½•æ•°ï¼š{count} æ¡\n"
                    f"ğŸ“‰ å¹³å‡å•ç¬”ï¼š{avg:.2f} å…ƒ\n\n"
                )
                result += format_records(records, limit=5)
                return result

            keyword_records = get_records_by_keyword(start_date=month_start, keyword=parsed["category"])
            keyword_total = sum(r["amount"] for r in keyword_records)
            keyword_count = len(keyword_records)
            keyword_avg = keyword_total / keyword_count if keyword_count else 0
            if keyword_count == 0:
                return "ğŸ“ æš‚æ— è®°å½•"

            result = (
                f"ğŸ” æœ¬æœˆåŒ…å«ã€Œ{parsed['category']}ã€çš„æ”¯å‡ºï¼š{keyword_total:.2f} å…ƒ\n"
                f"ğŸ§¾ è®°å½•æ•°ï¼š{keyword_count} æ¡\n"
                f"ğŸ“‰ å¹³å‡å•ç¬”ï¼š{keyword_avg:.2f} å…ƒ\n\n"
            )
            result += format_records(keyword_records, limit=5)
            return result
        except Exception as e:
            print(f"åˆ†ç±»æŸ¥è¯¢å¤±è´¥: {str(e)[:100]}")
            return "âŒ æŸ¥è¯¢å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
    
    elif parsed["type"] == "debt_add":
        try:
            new_amount = add_debt(parsed["name"], parsed["amount"], parsed.get("note", ""))
            note_text = f"\nå¤‡æ³¨ï¼š{parsed['note']}" if parsed.get("note") else ""
            return (
                "âœ… è®°è´¦æˆåŠŸï¼ˆæ¬ æ¬¾ï¼‰\n"
                f"é‡‘é¢ï¼š{parsed['amount']:.2f} å…ƒ\n"
                f"å…±æ¬ {parsed['name']} {new_amount:.2f}å…ƒ{note_text}"
            )
        except Exception as e:
            print(f"å¤–å€ºè®°å½•å¤±è´¥: {str(e)[:100]}")
            return "âŒ å¤–å€ºè®°å½•å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    elif parsed["type"] == "debt_repay":
        try:
            result = repay_debt(parsed["name"], parsed["amount"])
            if result.get("error") == "not_found":
                return f"âŒ æœªæ‰¾åˆ°æ¬ {parsed['name']}çš„è®°å½•"
            if result.get("error") == "overpay":
                return f"âŒ å½“å‰æ¬ {parsed['name']} {result['balance']:.2f} å…ƒï¼Œæœ¬æ¬¡è¿˜æ¬¾è¶…å‡ºï¼Œè¯·ä¿®æ”¹é‡‘é¢"
            if result["status"] == "paid":
                return (
                    "âœ… è®°è´¦æˆåŠŸï¼ˆè¿˜æ¬¾ï¼‰\n"
                    f"é‡‘é¢ï¼š{parsed['amount']:.2f} å…ƒ\n"
                    f"å·²è¿˜æ¸…æ¬ {parsed['name']}"
                )
            return (
                "âœ… è®°è´¦æˆåŠŸï¼ˆè¿˜æ¬¾ï¼‰\n"
                f"é‡‘é¢ï¼š{parsed['amount']:.2f} å…ƒ\n"
                f"è¿˜æ¬ {parsed['name']} {result['balance']:.2f}å…ƒ"
            )
        except Exception as e:
            print(f"å¤–å€ºè¿˜æ¬¾å¤±è´¥: {str(e)[:100]}")
            return "âŒ è¿˜æ¬¾å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    elif parsed["type"] == "debt_query_all":
        try:
            debts = list_debts()
            return format_debts(debts)
        except Exception as e:
            print(f"å¤–å€ºæŸ¥è¯¢å¤±è´¥: {str(e)[:100]}")
            return "âŒ å¤–å€ºæŸ¥è¯¢å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    elif parsed["type"] == "detail":
        try:
            period = parsed.get("period", "today")
            if period in ["ä»Šå¤©", "ä»Šæ—¥"]:
                start_date, end_date = get_date_range("today")
            elif period in ["æ˜¨å¤©", "æ˜¨æ—¥"]:
                start_date, end_date = get_date_range("yesterday")
            elif period in ["ä¸ƒå¤©", "è¿‘ä¸ƒå¤©"]:
                start_date, end_date = get_date_range("7days")
            elif period in ["åŠä¸ªæœˆ", "åäº”å¤©", "è¿‘åŠä¸ªæœˆ"]:
                start_date, end_date = get_date_range("15days")
            elif period in ["ä¸€ä¸ªæœˆ", "è¿‘ä¸€ä¸ªæœˆ", "30å¤©"]:
                start_date, end_date = get_date_range("30days")
            elif period == "æœ¬å‘¨":
                start_date, end_date = get_date_range("week")
            elif period == "æœ¬æœˆ":
                start_date, end_date = get_date_range("month")
            else:
                dt = parse_date_token(period)
                if not dt:
                    return "âŒ æ˜ç»†æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œç¤ºä¾‹ï¼šæ˜ç»† æ˜¨å¤© / æ˜ç»† 01-21"
                start_date = dt
                end_date = dt + timedelta(days=1) - timedelta(seconds=1)

            records = get_records(start_date=start_date, end_date=end_date)
            return format_records(records, limit=20)
        except Exception as e:
            print(f"æ˜ç»†æŸ¥è¯¢å¤±è´¥: {str(e)[:100]}")
            return "âŒ æŸ¥è¯¢å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    elif parsed["type"] == "export":
        try:
            target = parsed.get("target", "")
            mapping = {
                "ä»Šæ—¥": "today",
                "æ˜¨å¤©": "yesterday",
                "æ˜¨æ—¥": "yesterday",
                "ä¸ƒå¤©": "7days",
                "è¿‘ä¸ƒå¤©": "7days",
                "åŠä¸ªæœˆ": "15days",
                "åäº”å¤©": "15days",
                "è¿‘åŠä¸ªæœˆ": "15days",
                "ä¸€ä¸ªæœˆ": "30days",
                "è¿‘ä¸€ä¸ªæœˆ": "30days",
                "æœ¬å‘¨": "week",
                "æœ¬æœˆ": "month"
            }
            period_key = mapping.get(target, "month")
            export_link = build_export_link(openid, period_key)
            if not export_link:
                return "âŒ æœªé…ç½®å¯¼å‡ºåœ°å€ï¼Œè¯·å…ˆè®¾ç½® PUBLIC_BASE_URL"
            return f"ğŸ“¥ Excel å¯¼å‡ºé“¾æ¥ï¼ˆ10åˆ†é’Ÿå†…æœ‰æ•ˆï¼‰ï¼š\n{export_link}"
        except Exception as e:
            print(f"å¯¼å‡ºå¤±è´¥: {str(e)[:100]}")
            return "âŒ å¯¼å‡ºå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
    
    else:
        return "ğŸ¤” æ²¡ç†è§£ä½ çš„æ„æ€\n\nå‘é€ã€Œå¸®åŠ©ã€æŸ¥çœ‹ä½¿ç”¨è¯´æ˜"


# ============ å¾®ä¿¡å…¬ä¼—å·éªŒè¯ ============
def check_signature(signature, timestamp, nonce):
    """éªŒè¯å¾®ä¿¡æœåŠ¡å™¨ç­¾å"""
    tmp_arr = [TOKEN, timestamp, nonce]
    tmp_arr.sort()
    tmp_str = ''.join(tmp_arr)
    tmp_str = hashlib.sha1(tmp_str.encode('utf-8')).hexdigest()
    return tmp_str == signature


# ============ API è·¯ç”± ============
@app.get("/api/wechat")
async def verify(request: Request):
    """å¾®ä¿¡å…¬ä¼—å· URL éªŒè¯"""
    try:
        params = dict(request.query_params)
        signature = params.get("signature", "")
        timestamp = params.get("timestamp", "")
        nonce = params.get("nonce", "")
        echostr = params.get("echostr", "")
        
        if check_signature(signature, timestamp, nonce):
            return Response(content=echostr, media_type="text/plain")
        else:
            return Response(content="verify failed", status_code=403)
    except Exception as e:
        print(f"éªŒè¯é”™è¯¯: {str(e)[:100]}")
        return Response(content="error", status_code=500)


@app.get("/api/health")
async def health():
    """å¥åº·æ£€æŸ¥ï¼ˆä¿æ´»ç”¨ï¼‰"""
    return Response(content="ok", media_type="text/plain")


@app.post("/api/wechat")
async def webhook(request: Request):
    """æ¥æ”¶å¾®ä¿¡å…¬ä¼—å·æ¶ˆæ¯"""
    try:
        body = await request.body()
        body_str = body.decode("utf-8")
        
        # è§£æ XML
        from xml.etree import ElementTree as ET
        xml_tree = ET.fromstring(body_str)
        
        msg_type = xml_tree.find("MsgType").text
        from_user = xml_tree.find("FromUserName").text
        
        # åªå¤„ç†æ–‡æœ¬æ¶ˆæ¯
        if msg_type != "text":
            return Response(content="success", media_type="text/plain")
        
        content = xml_tree.find("Content").text
        
        # è·å–ç”¨æˆ·ä¿¡æ¯ï¼ˆå¯é€‰ï¼Œéœ€è¦ access_tokenï¼‰
        nickname = from_user[:8]  # æš‚æ—¶ç”¨ openid å‰8ä½ä½œä¸ºæ ‡è¯†
        
        # å¤„ç†æ¶ˆæ¯
        reply_content = handle_message(from_user, nickname, content)
        
        # æ„é€ å›å¤ XML
        to_user = xml_tree.find("FromUserName").text
        from_user_name = xml_tree.find("ToUserName").text
        create_time = int(time.time())
        
        reply_xml = f"""<xml>
<ToUserName><![CDATA[{to_user}]]></ToUserName>
<FromUserName><![CDATA[{from_user_name}]]></FromUserName>
<CreateTime>{create_time}</CreateTime>
<MsgType><![CDATA[text]]></MsgType>
<Content><![CDATA[{reply_content}]]></Content>
</xml>"""
        
        return Response(content=reply_xml, media_type="application/xml")
    except Exception as e:
        print(f"å¤„ç†æ¶ˆæ¯é”™è¯¯: {str(e)[:100]}")
        return Response(content="success", media_type="text/plain")


@app.get("/api/export")
async def export_excel(request: Request):
    """å¯¼å‡º Excel"""
    try:
        params = dict(request.query_params)
        openid = params.get("openid", "")
        period = params.get("period", "")
        ts = params.get("ts", "")
        sig = params.get("sig", "")

        if not verify_export_signature(openid, period, ts, sig):
            return Response(content="invalid", status_code=403)

        start_date, end_date = get_date_range(period)
        records = get_records(start_date=start_date, end_date=end_date)
        data = build_export_excel_bytes(records, start_date, end_date)
        filename = f"records-{period}.xlsx"
        headers = {"Content-Disposition": f'attachment; filename="{filename}"'}
        return StreamingResponse(io.BytesIO(data),
                                 media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                 headers=headers)
    except Exception as e:
        print(f"å¯¼å‡ºé”™è¯¯: {str(e)[:100]}")
        return Response(content="error", status_code=500)
